log4j.rootCategory=INFO, stdout

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{ABSOLUTE} %5p %t %c{2} - %m%n

# trim Hive logging
log4j.category.DataNucleus=ERROR
log4j.category.SessionState=FATAL
log4j.category.ExecMapper=WARN
log4j.category.org.apache.hadoop.hive.ql=WARN
log4j.category.org.apache.hadoop.hive.ql.Driver=WARN
log4j.category.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.category.org.apache.hadoop.hive.ql.exec=WARN

# ES-Hadoop logging
log4j.category.org.apache.hadoop.hive.metastore.HiveMetaStore=WARN
log4j.category.org.elasticsearch.hadoop.pig=INFO
#log4j.category.org.elasticsearch.hadoop=TRACE
#log4j.category.org.elasticsearch.hadoop.mr=TRACE
#log4j.category.org.elasticsearch.hadoop.rest=TRACE
#log4j.category.org.elasticsearch.hadoop.cascading=TRACE
#log4j.category.org.elasticsearch.hadoop.rest.commonshttp=TRACE
#log4j.category.org.elasticsearch.hadoop.serialization=TRACE

# Cascading
log4j.category.cascading=INFO

# Integration testing
log4j.category.org.elasticsearch.hadoop.integration.hive=INFO

# Pig
#log4j.category.org.apache.pig=WARN

# Spark
#log4j.category.org.elasticsearch.spark=TRACE

# Storm
# shut up ZK
log4j.category.org.apache.zookeeper=WARN
log4j.category.org.apache.curator=WARN
#log4j.category.org.elasticsearch.integration.storm=TRACE